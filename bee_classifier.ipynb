{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "YOLO_TRAIN_DIR = Path(\"/home/lex/data/Spatial_Monitoring_and_Insect_Behavioural_Analysis_Dataset/YOLOv4_Training_and_Test_Dataset/training\")\n",
    "YOLO_TEST_DIR = Path(\"/home/lex/data/Spatial_Monitoring_and_Insect_Behavioural_Analysis_Dataset/YOLOv4_Training_and_Test_Dataset/testing\")\n",
    "CLASSIFIER_TRAIN_DIR = Path(\"out/classification/training\")\n",
    "CLASSIFIER_TEST_DIR = Path(\"out/classification/testing\")\n",
    "\n",
    "CLASSIFIER_TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLASSIFIER_TEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INSECT_TXT_REGEX = re.compile(r\"insect_(\\d+).txt\")\n",
    "\n",
    "TRAIN = \"train\"\n",
    "TEST = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    honeybee_vespidae\n",
       "1               flower\n",
       "2            syrphidae\n",
       "3          lepidoptera\n",
       "Name: target_name, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of target classes (e.g. bee/wasp, flower, etc.) and corresponding zero-based index for that class\n",
    "TARGET_TO_NAME = pd.Series(\n",
    "    {\n",
    "        0: \"honeybee_vespidae\", \n",
    "        1: \"flower\", \n",
    "        2: \"syrphidae\", \n",
    "        3: \"lepidoptera\"\n",
    "    }, \n",
    "    name=\"target_name\"\n",
    ")\n",
    "NAME_TO_TARGET = {v: k for k, v in TARGET_TO_NAME.items()}\n",
    "TARGET_TO_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>centre_x</th>\n",
       "      <th>centre_y</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438305</td>\n",
       "      <td>0.512250</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.033593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131612</td>\n",
       "      <td>0.412750</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.035130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394792</td>\n",
       "      <td>0.306481</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.025926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294792</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514062</td>\n",
       "      <td>0.241204</td>\n",
       "      <td>0.038542</td>\n",
       "      <td>0.065741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image target  centre_x  \\\n",
       "0  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.438305   \n",
       "1  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.131612   \n",
       "2  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.394792   \n",
       "3  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1  0.294792   \n",
       "4  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1  0.514062   \n",
       "\n",
       "   centre_y  box_width  box_height  \n",
       "0  0.512250   0.016172    0.033593  \n",
       "1  0.412750   0.011568    0.035130  \n",
       "2  0.306481   0.017708    0.025926  \n",
       "3  0.488889   0.030208    0.055556  \n",
       "4  0.241204   0.038542    0.065741  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get DataFrame where each row corresponds to a unique image+bounding box for every\n",
    "# instance of an insect that occurs in the (full-resolution) training images\n",
    "csv_columns = [\"target\", \"centre_x\", \"centre_y\", \"box_width\", \"box_height\"]\n",
    "extra_columns = [\"image\"]\n",
    "\n",
    "dataframes = {\n",
    "    \"train\": pd.DataFrame(columns=[*extra_columns, *csv_columns]),\n",
    "    \"test\": pd.DataFrame(columns=[*extra_columns, *csv_columns])\n",
    "}\n",
    "\n",
    "for directory, phase in zip([YOLO_TRAIN_DIR, YOLO_TEST_DIR], [TRAIN, TEST]):\n",
    "    for file in directory.iterdir():\n",
    "        match = INSECT_TXT_REGEX.match(file.name)\n",
    "        if match:\n",
    "            row = pd.read_csv(file, sep=\" \", names=csv_columns)\n",
    "            \n",
    "            # Get corresponding image for this insect \n",
    "            image_fp = file.with_suffix(\".png\")\n",
    "            row[\"image\"] = str(image_fp)\n",
    "\n",
    "            dataframes[phase] = pd.concat([dataframes[phase], row], ignore_index=True)\n",
    "\n",
    "dataframes[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>centre_x</th>\n",
       "      <th>centre_y</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438305</td>\n",
       "      <td>0.512250</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.033593</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131612</td>\n",
       "      <td>0.412750</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394792</td>\n",
       "      <td>0.306481</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294792</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514062</td>\n",
       "      <td>0.241204</td>\n",
       "      <td>0.038542</td>\n",
       "      <td>0.065741</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image target  centre_x  \\\n",
       "0  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.438305   \n",
       "1  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.131612   \n",
       "2  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0  0.394792   \n",
       "3  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1  0.294792   \n",
       "4  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1  0.514062   \n",
       "\n",
       "   centre_y  box_width  box_height        target_name  \n",
       "0  0.512250   0.016172    0.033593  honeybee_vespidae  \n",
       "1  0.412750   0.011568    0.035130  honeybee_vespidae  \n",
       "2  0.306481   0.017708    0.025926  honeybee_vespidae  \n",
       "3  0.488889   0.030208    0.055556             flower  \n",
       "4  0.241204   0.038542    0.065741             flower  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add insect type as human-friendly string to dataframe just because\n",
    "for phase in [TRAIN, TEST]:\n",
    "    dataframes[phase] = dataframes[phase].join(TARGET_TO_NAME, on=\"target\")\n",
    "\n",
    "dataframes[TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_insect(image: np.ndarray, centre_x: int, centre_y: int, height_width:int=128):\n",
    "    \"\"\"Convert a row from our insect bounding boxes DataFrame into a cropped image.\"\"\"\n",
    "    # Note we're not actually using the original height/width of bounding boxes, \n",
    "    # we want something a little less precise and more consistent\n",
    "    top_y = int(centre_y - 0.5 * height_width)\n",
    "    bottom_y = int(centre_y + 0.5 * height_width)\n",
    "    left_x = int(centre_x - 0.5 * height_width)\n",
    "    right_x = int(centre_x + 0.5 * height_width)\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # print(f\"Before, top_y={top_y}, bottom_y={bottom_y}, left_x={left_x}, right_x={right_x}\")\n",
    "    # Check if our crop goes out of bounds\n",
    "    pad_width = [[0, 0], [0, 0], [0, 0]] # padding width for (before, after) for each axis of image arrays\n",
    "    if top_y < 0:\n",
    "        pad_width[0][0] = abs(top_y)\n",
    "        bottom_y += abs(top_y)\n",
    "        top_y = 0\n",
    "    if bottom_y > height:\n",
    "        pad_width[0][1] = abs(bottom_y - height) + 1\n",
    "    if left_x < 0:\n",
    "        pad_width[1][0] = abs(left_x)\n",
    "        right_x += abs(left_x)\n",
    "        left_x = 0\n",
    "    if right_x > width:\n",
    "        pad_width[1][1] = abs(right_x - width) + 1\n",
    "    # print(f\"After, top_y={top_y}, bottom_y={bottom_y}, left_x={left_x}, right_x={right_x}\")\n",
    "\n",
    "    image_padded = np.pad(image, pad_width=pad_width, mode=\"symmetric\")\n",
    "    image_cropped = image_padded[top_y:bottom_y, left_x:right_x]\n",
    "\n",
    "    return image_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/ and testing/ directories for 'honeybee_vespidae' in 'out/classification/training' and 'out/classification/testing', respectively\n",
      "Creating training/ and testing/ directories for 'flower' in 'out/classification/training' and 'out/classification/testing', respectively\n",
      "Creating training/ and testing/ directories for 'syrphidae' in 'out/classification/training' and 'out/classification/testing', respectively\n",
      "Creating training/ and testing/ directories for 'lepidoptera' in 'out/classification/training' and 'out/classification/testing', respectively\n"
     ]
    }
   ],
   "source": [
    "# Make sure our output directories exist before we put files into them\n",
    "for target in TARGET_TO_NAME:\n",
    "    print(f\"Creating training/ and testing/ directories for '{target}' in '{CLASSIFIER_TRAIN_DIR}' and '{CLASSIFIER_TEST_DIR}', respectively\")\n",
    "    (CLASSIFIER_TRAIN_DIR / target).mkdir(parents=True, exist_ok=True)\n",
    "    (CLASSIFIER_TEST_DIR / target).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 16550/16550 [13:11<00:00, 20.91it/s]\n",
      "test: 100%|██████████| 3246/3246 [02:32<00:00, 21.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>centre_x</th>\n",
       "      <th>centre_y</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>target_name</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>841</td>\n",
       "      <td>553</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>445</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>330</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>honeybee_vespidae</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "      <td>528</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>flower</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/lex/data/Spatial_Monitoring_and_Insect_B...</td>\n",
       "      <td>1</td>\n",
       "      <td>986</td>\n",
       "      <td>260</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>flower</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image target  centre_x  \\\n",
       "0  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0       841   \n",
       "1  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0       252   \n",
       "2  /home/lex/data/Spatial_Monitoring_and_Insect_B...      0       758   \n",
       "3  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1       566   \n",
       "4  /home/lex/data/Spatial_Monitoring_and_Insect_B...      1       986   \n",
       "\n",
       "   centre_y  box_width  box_height        target_name  image_height  \\\n",
       "0       553         31          36  honeybee_vespidae          1080   \n",
       "1       445         22          37  honeybee_vespidae          1080   \n",
       "2       330         33          28  honeybee_vespidae          1080   \n",
       "3       528         57          60             flower          1080   \n",
       "4       260         74          71             flower          1080   \n",
       "\n",
       "   image_width  \n",
       "0         1920  \n",
       "1         1920  \n",
       "2         1920  \n",
       "3         1920  \n",
       "4         1920  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now convert those fractional positions above to absolute pixel values (e.g. \n",
    "# centre_x=0.44 --> 0.44*1920~=845)\n",
    "for phase, input_dir, output_dir in zip([TRAIN, TEST], [YOLO_TRAIN_DIR, YOLO_TEST_DIR], [CLASSIFIER_TRAIN_DIR, CLASSIFIER_TEST_DIR]):\n",
    "    df = dataframes[phase]\n",
    "\n",
    "    # We'll store these back into the dataframe to store the integer, not fractional,\n",
    "    # measurements. All images are probably the same resolution, but do it this\n",
    "    # way just in case there are differing resolutions\n",
    "    centre_ys = pd.Series(index=df.index, name=\"centre_y\", dtype=int)\n",
    "    centre_xs = pd.Series(index=df.index, name=\"centre_x\", dtype=int)\n",
    "    box_heights = pd.Series(index=df.index, name=\"box_height\", dtype=int)\n",
    "    box_widths = pd.Series(index=df.index, name=\"box_width\", dtype=int)\n",
    "    image_heights = pd.Series(index=df.index, name=\"image_height\", dtype=int)\n",
    "    image_widths = pd.Series(index=df.index, name=\"image_width\", dtype=int)\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=phase):\n",
    "        row = row.squeeze()\n",
    "\n",
    "        input_fp = input_dir / row[\"image\"]\n",
    "        image = cv2.imread(str(input_fp))\n",
    "        image_height, image_width, num_channels = image.shape\n",
    "\n",
    "        # Store conversions from fractional to absolute values for later reuse\n",
    "        centre_y = int(row[\"centre_y\"] * image_height)\n",
    "        centre_x = int(row[\"centre_x\"] * image_width)\n",
    "        box_height = int(row[\"box_height\"] * image_height)\n",
    "        box_width = int(row[\"box_width\"] * image_width)\n",
    "\n",
    "        # Crop image and save to output directory\n",
    "        image_cropped = crop_to_insect(image=image, centre_x=centre_x, centre_y=centre_y)\n",
    "\n",
    "        input_stem = input_fp.stem\n",
    "        input_suffix = input_fp.suffix\n",
    "        target_name = row[\"target_name\"]\n",
    "        \n",
    "        output_name = f\"{input_stem}_{row['target']}_{centre_x}_{centre_y}{input_suffix}\"\n",
    "        output_fp = output_dir / target_name / output_name\n",
    "        # print(output_fp)\n",
    "        \n",
    "        cv2.imwrite(str(output_fp), image_cropped)\n",
    "\n",
    "        # Save these as integers, maybe for later\n",
    "        centre_ys[index] = centre_y\n",
    "        centre_xs[index] = centre_x\n",
    "        box_heights[index] = box_height\n",
    "        box_widths[index] = box_width\n",
    "        image_heights[index] = image_height\n",
    "        image_widths[index] = image_width\n",
    "    \n",
    "    dataframes[phase] = df.assign(\n",
    "        centre_y=centre_ys,\n",
    "        centre_x=centre_xs,\n",
    "        box_height=box_heights,\n",
    "        box_width=box_widths,\n",
    "        image_height=image_heights,\n",
    "        image_width=image_widths\n",
    "    )\n",
    "    dataframes[phase] = dataframes[phase].astype({\n",
    "        \"centre_y\": int,\n",
    "        \"centre_x\": int,\n",
    "        \"box_height\": int,\n",
    "        \"box_width\": int,\n",
    "        \"image_height\": int,\n",
    "        \"image_width\": int\n",
    "    })\n",
    "    \n",
    "    \n",
    "dataframes[TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torch.utils.data import SubsetRandomSampler, Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from typing import Tuple, List, Dict, Optional, Callable, Any, Union\n",
    "import os\n",
    "\n",
    "\n",
    "class InsectDataset(Dataset):\n",
    "    def __init__(self, directory: Union[Path, str]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not isinstance(directory, Path):\n",
    "            directory = Path(directory)\n",
    "        self.directory = directory\n",
    "\n",
    "        self.class_names = self.find_class_names()\n",
    "        self.images = self.find_images()\n",
    "\n",
    "        self.transform = transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(32),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def find_class_names(self):\n",
    "        class_names = [fp.name for fp in self.directory.iterdir() if fp.is_dir()]\n",
    "        return class_names\n",
    "\n",
    "    def find_images(self) -> List[str]:\n",
    "        images = []\n",
    "        for class_name in self.class_names:\n",
    "            class_index = NAME_TO_TARGET[class_name]\n",
    "            class_dir = self.directory / class_name\n",
    "            images.extend([(video_file, class_index) for video_file in class_dir.iterdir()])\n",
    "        \n",
    "        return images\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_fp, target = self.images[index]\n",
    "        image = default_loader(image_fp)\n",
    "        image = self.transform(image)\n",
    "        # print(f\"In dataset, image shape is {image.shape}\")\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"InsectDataset (directory={self.directory}, {len(self)} images)\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "train_dataset = InsectDataset(CLASSIFIER_TRAIN_DIR)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = InsectDataset(CLASSIFIER_TEST_DIR)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.036\n",
      "[1,   200] loss: 0.020\n",
      "[1,   300] loss: 0.020\n",
      "[1,   400] loss: 0.021\n",
      "[1,   500] loss: 0.018\n",
      "[2,   100] loss: 0.016\n",
      "[2,   200] loss: 0.016\n",
      "[2,   300] loss: 0.014\n",
      "[2,   400] loss: 0.012\n",
      "[2,   500] loss: 0.013\n",
      "[3,   100] loss: 0.011\n",
      "[3,   200] loss: 0.012\n",
      "[3,   300] loss: 0.009\n",
      "[3,   400] loss: 0.011\n",
      "[3,   500] loss: 0.009\n",
      "[4,   100] loss: 0.009\n",
      "[4,   200] loss: 0.008\n",
      "[4,   300] loss: 0.008\n",
      "[4,   400] loss: 0.009\n",
      "[4,   500] loss: 0.007\n",
      "[5,   100] loss: 0.007\n",
      "[5,   200] loss: 0.008\n",
      "[5,   300] loss: 0.008\n",
      "[5,   400] loss: 0.006\n",
      "[5,   500] loss: 0.007\n",
      "[6,   100] loss: 0.006\n",
      "[6,   200] loss: 0.005\n",
      "[6,   300] loss: 0.007\n",
      "[6,   400] loss: 0.006\n",
      "[6,   500] loss: 0.006\n",
      "[7,   100] loss: 0.006\n",
      "[7,   200] loss: 0.005\n",
      "[7,   300] loss: 0.006\n",
      "[7,   400] loss: 0.005\n",
      "[7,   500] loss: 0.005\n",
      "[8,   100] loss: 0.006\n",
      "[8,   200] loss: 0.005\n",
      "[8,   300] loss: 0.006\n",
      "[8,   400] loss: 0.005\n",
      "[8,   500] loss: 0.005\n",
      "[9,   100] loss: 0.004\n",
      "[9,   200] loss: 0.005\n",
      "[9,   300] loss: 0.006\n",
      "[9,   400] loss: 0.005\n",
      "[9,   500] loss: 0.005\n",
      "[10,   100] loss: 0.005\n",
      "[10,   200] loss: 0.004\n",
      "[10,   300] loss: 0.005\n",
      "[10,   400] loss: 0.005\n",
      "[10,   500] loss: 0.004\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(TARGET_TO_NAME))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = F.relu(y)\n",
    "        y = self.pool(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.pool(y)\n",
    "\n",
    "        y = torch.flatten(y, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        y = self.fc2(y)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        y = self.fc3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "        # print(f\"Shape here is {images.shape}\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: honeybee_vespidae is 98.7 %\n",
      "Accuracy for class: flower is 98.5 %\n",
      "Accuracy for class: syrphidae is 0.0 %\n",
      "Accuracy for class: lepidoptera is 13.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in NAME_TO_TARGET}\n",
    "total_pred = {classname: 0 for classname in NAME_TO_TARGET}\n",
    "max_vals_list = np.array([])\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        max_vals, predictions = torch.max(outputs, 1)\n",
    "        max_vals_list = np.concatenate([max_vals_list, max_vals.numpy()])\n",
    "\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[TARGET_TO_NAME[int(label)]] += 1\n",
    "            total_pred[TARGET_TO_NAME[int(label)]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3119,  0.0328, -1.2583,  0.0039]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "fake_image = torch.rand((1, 3, 32, 32)) * 2 - 1\n",
    "net(fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities used in predictions were: 6.029759963918122 +- 2.039279442263269 (range: 0.15661728382110596 to 8.838119506835938)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probabilities used in predictions were: {max_vals_list.mean()} +- {max_vals_list.std()} (range: {max_vals_list.min()} to {max_vals_list.max()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals_list.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57413983, 0.15661728, 0.32433099, ..., 2.63999248, 1.05817676,\n",
       "       1.6402936 ])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8353,  0.8039,  0.8980,  ...,  0.7255,  0.7961,  0.8118],\n",
       "          [ 0.7569,  0.7725,  0.9294,  ...,  0.5922,  0.6392,  0.6941],\n",
       "          [ 0.7412,  0.7569,  0.9137,  ...,  0.5765,  0.5922,  0.6314],\n",
       "          ...,\n",
       "          [ 0.2235,  0.1686,  0.1216,  ...,  0.4588,  0.5059,  0.5451],\n",
       "          [ 0.2863,  0.1922,  0.1529,  ...,  0.4980,  0.5294,  0.5529],\n",
       "          [ 0.3804,  0.2549,  0.2078,  ...,  0.5608,  0.5529,  0.5529]],\n",
       " \n",
       "         [[ 0.8510,  0.8196,  0.8510,  ...,  0.3176,  0.3804,  0.3961],\n",
       "          [ 0.7725,  0.7882,  0.8745,  ...,  0.1765,  0.2235,  0.2784],\n",
       "          [ 0.7569,  0.7725,  0.8588,  ...,  0.1608,  0.1765,  0.2157],\n",
       "          ...,\n",
       "          [-0.3176, -0.3725, -0.4039,  ...,  0.0039,  0.0510,  0.0902],\n",
       "          [-0.2549, -0.3490, -0.3725,  ...,  0.0431,  0.0745,  0.0980],\n",
       "          [-0.1686, -0.2941, -0.3098,  ...,  0.0902,  0.0980,  0.0980]],\n",
       " \n",
       "         [[ 0.2941,  0.2627,  0.3333,  ..., -0.2392, -0.1529, -0.1373],\n",
       "          [ 0.2157,  0.2314,  0.3412,  ..., -0.3569, -0.2941, -0.2392],\n",
       "          [ 0.2000,  0.2157,  0.3255,  ..., -0.3725, -0.3412, -0.3020],\n",
       "          ...,\n",
       "          [-0.7412, -0.7961, -0.8118,  ..., -0.4118, -0.3647, -0.3255],\n",
       "          [-0.6784, -0.7725, -0.7804,  ..., -0.3725, -0.3412, -0.3176],\n",
       "          [-0.6235, -0.7490, -0.7569,  ..., -0.3333, -0.3333, -0.3333]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcb72ef4c0ea3c595b2bc6c703ebc010c810e467f84455861e032fc300b00f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
