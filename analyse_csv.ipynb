{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          video_source  reader_sleep_seconds  \\\n",
      "0    data/strawberry/cam_3_S_video_20210312_123203....                     5   \n",
      "1    data/strawberry/cam_3_S_video_20210312_123203....                     5   \n",
      "2    data/strawberry/cam_4_N_video_20210309_132604....                     5   \n",
      "3    data/strawberry/cam_4_N_video_20210317_114802....                     5   \n",
      "4    data/strawberry/cam_3_S_video_20210312_123203....                     5   \n",
      "..                                                 ...                   ...   \n",
      "155  data/strawberry/cam_1_N_video_20210315_132804....                     5   \n",
      "156  data/strawberry/cam_1_S_video_20210317_123004....                     5   \n",
      "157  data/strawberry/cam_2_S_video_20210308_112402....                     5   \n",
      "158  data/strawberry/cam_4_N_video_20210309_132604....                     5   \n",
      "159  data/strawberry/cam_8_N_video_20210310_133844....                     5   \n",
      "\n",
      "     reader_flush_proportion  downscale_factor  dilate_kernel_size  \\\n",
      "0                        0.9                16                  41   \n",
      "1                        0.9                16                  63   \n",
      "2                        0.9                 1                  63   \n",
      "3                        0.9                16                  41   \n",
      "4                        0.9                16                  41   \n",
      "..                       ...               ...                 ...   \n",
      "155                      0.9                 1                  63   \n",
      "156                      0.9                16                  41   \n",
      "157                      0.9                16                  41   \n",
      "158                      0.9                 1                  41   \n",
      "159                      0.9                 1                  63   \n",
      "\n",
      "     movement_threshold  persist_factor  num_opencv_threads  \\\n",
      "0                    40            0.65                  10   \n",
      "1                    40            0.75                  10   \n",
      "2                    50            0.75                  10   \n",
      "3                    40            0.75                  10   \n",
      "4                    40            0.75                  10   \n",
      "..                  ...             ...                 ...   \n",
      "155                  50            0.75                  10   \n",
      "156                  40            0.75                  10   \n",
      "157                  50            0.65                  10   \n",
      "158                  40            0.65                  10   \n",
      "159                  40            0.65                  10   \n",
      "\n",
      "                 start_datetime  input_duration_seconds  \\\n",
      "0    2022-12-12 20:52:38.411141              600.000000   \n",
      "1    2022-12-12 20:40:28.033166              600.000000   \n",
      "2    2022-12-13 03:53:55.990695              600.066667   \n",
      "3    2022-12-12 13:14:27.738835              600.133333   \n",
      "4    2022-12-12 20:56:38.559556              600.000000   \n",
      "..                          ...                     ...   \n",
      "155  2022-12-13 01:55:31.462176              598.900000   \n",
      "156  2022-12-12 19:02:07.627990              600.400000   \n",
      "157  2022-12-12 17:10:38.881924              600.133333   \n",
      "158  2022-12-13 04:04:01.219053              600.066667   \n",
      "159  2022-12-12 21:08:38.800966              600.100000   \n",
      "\n",
      "     processing_duration_seconds  input_filesize_MB  output_filesize_MB  \n",
      "0                         240.13        1179.422966           53.330218  \n",
      "1                         240.03        1179.422966           55.512420  \n",
      "2                         605.22        1074.495404           82.275608  \n",
      "3                         240.04        1024.980056           55.691632  \n",
      "4                         240.03        1179.422966           54.394690  \n",
      "..                           ...                ...                 ...  \n",
      "155                       636.51        1264.504246           91.566592  \n",
      "156                       240.03        1319.241340           53.302272  \n",
      "157                       240.14        1296.294376           51.691148  \n",
      "158                       540.08        1074.495404           79.327364  \n",
      "159                       755.10        1013.734438          299.779022  \n",
      "\n",
      "[160 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(\"test_files.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processing_speed_pct\"] = df[\"processing_duration_seconds\"] / df[\"input_duration_seconds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"output_filesize_pct\"] = df[\"output_filesize_MB\"] / df[\"input_filesize_MB\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see all the unique downscale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  1]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"downscale_factor\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the average filesize/processing speed reduction grouped by each of these downscale factors, so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  output_filesize_pct  processing_speed_pct\n",
      "downscale_factor                                           \n",
      "1                            0.111787              1.068993\n",
      "16                           0.054679              0.410763\n",
      "                  output_filesize_pct  processing_speed_pct\n",
      "downscale_factor                                           \n",
      "1                            0.071555              0.099926\n",
      "16                           0.021552              0.013474\n"
     ]
    }
   ],
   "source": [
    "downscale_groups = df.groupby(\"downscale_factor\")\n",
    "print(downscale_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].mean())\n",
    "print(downscale_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat this for dilation kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    output_filesize_pct  processing_speed_pct\n",
      "dilate_kernel_size                                           \n",
      "41                             0.081410              0.730206\n",
      "63                             0.085056              0.749550\n",
      "                    output_filesize_pct  processing_speed_pct\n",
      "dilate_kernel_size                                           \n",
      "41                             0.059812              0.328586\n",
      "63                             0.060429              0.348403\n"
     ]
    }
   ],
   "source": [
    "dilation_groups = df.groupby(\"dilate_kernel_size\")\n",
    "print(dilation_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].mean())\n",
    "print(dilation_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for movement threshold. Presumably, a smaller threshold means more pixels are included in output file, so would expect that filesize is greater, but processing time should be basically the same I would imagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    output_filesize_pct  processing_speed_pct\n",
      "movement_threshold                                           \n",
      "40                             0.093074              0.753457\n",
      "50                             0.073391              0.726299\n",
      "                    output_filesize_pct  processing_speed_pct\n",
      "movement_threshold                                           \n",
      "40                             0.067743              0.348843\n",
      "50                             0.049504              0.327838\n"
     ]
    }
   ],
   "source": [
    "movement_thresh_groups = df.groupby(\"movement_threshold\")\n",
    "print(movement_thresh_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].mean())\n",
    "print(movement_thresh_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check out the persist factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                output_filesize_pct  processing_speed_pct\n",
      "persist_factor                                           \n",
      "0.65                       0.074011              0.722360\n",
      "0.75                       0.092454              0.757396\n",
      "                output_filesize_pct  processing_speed_pct\n",
      "persist_factor                                           \n",
      "0.65                       0.050237              0.324555\n",
      "0.75                       0.067379              0.351547\n"
     ]
    }
   ],
   "source": [
    "persist_groups = df.groupby(\"persist_factor\")\n",
    "print(persist_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].mean())\n",
    "print(persist_groups[[\"output_filesize_pct\", \"processing_speed_pct\"]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('bees-edge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcb72ef4c0ea3c595b2bc6c703ebc010c810e467f84455861e032fc300b00f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
